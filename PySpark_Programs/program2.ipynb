from pyspark import SparkContext

# Create a SparkContext
sc = SparkContext("local", "test")

# Set the log level to INFO
# sc.setLogLevel("NONE")

# You can now perform your Spark operations
# For example, creating an RDD
data = [1, 2, 3, 4, 5]
rdd = sc.parallelize(data)

# Perform an action
print(rdd.collect())

# Stop the SparkContext when done
sc.stop()
